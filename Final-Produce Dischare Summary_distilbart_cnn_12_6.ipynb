{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e14778774573423f80ea12b4c159b604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5142ebc604354707a59e3a89947f12fa",
              "IPY_MODEL_2b28f4138c6d4c4794a6fcb89a04e8e2",
              "IPY_MODEL_ca55c674bcd94494a7de0a99f2ec7c6c"
            ],
            "layout": "IPY_MODEL_2364980adef64751b08bbab51e9eb239"
          }
        },
        "5142ebc604354707a59e3a89947f12fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c41f6f0ebca421fb2d7a22809c0c52a",
            "placeholder": "​",
            "style": "IPY_MODEL_f2c25a15889e45d5b0aadcb58d8ef38b",
            "value": "100%"
          }
        },
        "2b28f4138c6d4c4794a6fcb89a04e8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff5ef3f234fe4837a007f71158d2e26c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_428640bf1cbb485e81c604c4160deb81",
            "value": 1
          }
        },
        "ca55c674bcd94494a7de0a99f2ec7c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afbe586f64a54b7fbed583524a6f2f47",
            "placeholder": "​",
            "style": "IPY_MODEL_7591e1c168284e67baa69f03db96d41f",
            "value": " 1/1 [00:00&lt;00:00, 55.92it/s]"
          }
        },
        "2364980adef64751b08bbab51e9eb239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c41f6f0ebca421fb2d7a22809c0c52a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2c25a15889e45d5b0aadcb58d8ef38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff5ef3f234fe4837a007f71158d2e26c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "428640bf1cbb485e81c604c4160deb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afbe586f64a54b7fbed583524a6f2f47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7591e1c168284e67baa69f03db96d41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2ac3ed12ad243d4afe3b17919dec71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af4da2e30f24439a89f9c729282b8145",
              "IPY_MODEL_af545badcb054574bf9e618da9158769",
              "IPY_MODEL_ffd7bf5af3824965b54af81402de51fa"
            ],
            "layout": "IPY_MODEL_224b576a802f40e7bc185d0430098df7"
          }
        },
        "af4da2e30f24439a89f9c729282b8145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93cb3297a5ff462a888e2b9ea74a4261",
            "placeholder": "​",
            "style": "IPY_MODEL_da9cf9b7019143559e47e13bdec6a9ae",
            "value": "Map: 100%"
          }
        },
        "af545badcb054574bf9e618da9158769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09d301cc9bcd4fe8af4f381c910c9a12",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e73c61ca07a43baa40d1ddfbd811aab",
            "value": 1000
          }
        },
        "ffd7bf5af3824965b54af81402de51fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8527f16d972a46ae94e3bf087fc9319b",
            "placeholder": "​",
            "style": "IPY_MODEL_1790ade1106747dcbcd502227cf9effe",
            "value": " 1000/1000 [00:08&lt;00:00, 124.82 examples/s]"
          }
        },
        "224b576a802f40e7bc185d0430098df7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "93cb3297a5ff462a888e2b9ea74a4261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da9cf9b7019143559e47e13bdec6a9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09d301cc9bcd4fe8af4f381c910c9a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e73c61ca07a43baa40d1ddfbd811aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8527f16d972a46ae94e3bf087fc9319b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1790ade1106747dcbcd502227cf9effe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**An Automated Discharge Summary system Built for\n",
        "Multiple Clinical Texts by Pre-trained distilbart Model**"
      ],
      "metadata": {
        "id": "HaFnDDS1ewBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code mounts Google Drive into the Colab environment, allowing access to files and folders stored in the Google Drive."
      ],
      "metadata": {
        "id": "QGC-HTcrexEV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhbWb8oaeuDm",
        "outputId": "dca7ea16-324a-4117-8658-53aa1a1c1f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installind and importing necessary libraries"
      ],
      "metadata": {
        "id": "DGfGGxqCfOvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouvyJm-SfZcl",
        "outputId": "0a0c9b0f-6d24-4009-e72a-5edbdeb9a42c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBheGH_vfZiE",
        "outputId": "fe77a4ec-107f-42ca-d1d8-f8b0356503b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BartTokenizer, TFBartForConditionalGeneration\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "aNmzGIjEfZm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code reads a CSV dataset named \"sample_data_1000.csv\" from the mounted Google Drive and loads it into a variable called \"Dataset_for_BART_Model.\" Then, it uses the Hugging Face's `load_dataset` function to load the same CSV dataset into a variable called \"ds.\""
      ],
      "metadata": {
        "id": "2awrCpVGfjb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset_for_BART_Model = pd.read_csv('/content/drive/MyDrive/sample_data_1000.csv')\n",
        "ds = load_dataset('csv',data_files = '/content/drive/MyDrive/sample_data_1000.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "e14778774573423f80ea12b4c159b604",
            "5142ebc604354707a59e3a89947f12fa",
            "2b28f4138c6d4c4794a6fcb89a04e8e2",
            "ca55c674bcd94494a7de0a99f2ec7c6c",
            "2364980adef64751b08bbab51e9eb239",
            "7c41f6f0ebca421fb2d7a22809c0c52a",
            "f2c25a15889e45d5b0aadcb58d8ef38b",
            "ff5ef3f234fe4837a007f71158d2e26c",
            "428640bf1cbb485e81c604c4160deb81",
            "afbe586f64a54b7fbed583524a6f2f47",
            "7591e1c168284e67baa69f03db96d41f"
          ]
        },
        "id": "GF8EBjmpfZpk",
        "outputId": "e146ce28-b916-4046-c62a-231fe57d8964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-7e75b6d0e47bccb5/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e14778774573423f80ea12b4c159b604"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_string(example):\n",
        "  for key in example.keys():\n",
        "    example[key] = str(example[key])\n",
        "  return example\n",
        "\n",
        "ds = ds.map(convert_to_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaClVqJrfZu1",
        "outputId": "0ba60077-68d4-44ee-f00a-cca681f7ee28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-7e75b6d0e47bccb5/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-f7c8ba422e68e7ce.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://huggingface.co/philschmid/tf-distilbart-cnn-12-6.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPM3pJEsfZ0E",
        "outputId": "303564f6-9487-43a4-9651-48d255634261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'tf-distilbart-cnn-12-6' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"philschmid/tf-distilbart-cnn-12-6\""
      ],
      "metadata": {
        "id": "fzlDhH0qfZ3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code imports a configuration class called \"BartConfig\" from the Hugging Face's Transformers library. It then creates a BART model configuration by loading a pre-trained configuration named \"philschmid/tf-distilbart-cnn-12-6.\" The code accesses the maximum input dimension of the BART model configuration and stores it in the variable \"max_input_dimension.\""
      ],
      "metadata": {
        "id": "3CtebeUlgHUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartConfig\n",
        "\n",
        "# Create a BART model configuration\n",
        "config = BartConfig.from_pretrained(\"philschmid/tf-distilbart-cnn-12-6\")\n",
        "\n",
        "# Access the maximum input dimension\n",
        "max_input_dimension = config.max_position_embeddings\n",
        "\n",
        "print(\"Maximum Input Dimension:\", max_input_dimension)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1I0k-d7fZ9l",
        "outputId": "d31df066-08f4-4ee4-d626-603ab1dd7582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Input Dimension: 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n"
      ],
      "metadata": {
        "id": "iuOirm_Yf4cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing dataset"
      ],
      "metadata": {
        "id": "uROgt5oEgPmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "uPQWs9Muf4fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_remove_columns = ['HADM_ID', 'ECG', 'Echo', 'Nursing', 'Physician ', 'Radiology']\n",
        "\n",
        "ds = ds[\"train\"].remove_columns(to_remove_columns)\n"
      ],
      "metadata": {
        "id": "6gn5jxcUf4ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvNAikS0gjKW",
        "outputId": "53ce99a0-7128-48d4-a550-db5b42d80626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_input_length = 500 #400 #4000 #47000\n",
        "max_target_length = 200 #200 #1000 #10700\n",
        "#(10681.578, 46985.783)\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    stop_words = set(stopwords.words('english')) # Get the English stop words\n",
        "\n",
        "    # Define a function to remove stop words from a given text\n",
        "    def remove_stop_words(text):\n",
        "        tokens = text.split()\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "        return ' '.join(filtered_tokens)\n",
        "\n",
        "    # Remove stop words from examples['Concatenated_Text']\n",
        "    examples['Concatenated_Text'] = [remove_stop_words(text) for text in examples['Concatenated_Text']]\n",
        "\n",
        "    # Remove stop words from examples['Discharge summary']\n",
        "    examples['Discharge summary'] = [remove_stop_words(text) for text in examples['Discharge summary']]\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        examples['Concatenated_Text'],\n",
        "        max_length=max_input_length,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            examples['Discharge summary'],\n",
        "            max_length=max_target_length,\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    model_inputs[\"references\"] = examples['Discharge summary']\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_datasets = ds.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91,
          "referenced_widgets": [
            "a2ac3ed12ad243d4afe3b17919dec71b",
            "af4da2e30f24439a89f9c729282b8145",
            "af545badcb054574bf9e618da9158769",
            "ffd7bf5af3824965b54af81402de51fa",
            "224b576a802f40e7bc185d0430098df7",
            "93cb3297a5ff462a888e2b9ea74a4261",
            "da9cf9b7019143559e47e13bdec6a9ae",
            "09d301cc9bcd4fe8af4f381c910c9a12",
            "5e73c61ca07a43baa40d1ddfbd811aab",
            "8527f16d972a46ae94e3bf087fc9319b",
            "1790ade1106747dcbcd502227cf9effe"
          ]
        },
        "id": "BlEuB9tBgM7x",
        "outputId": "060d2632-cce7-4a46-ced3-c483c03466cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.fingerprint:Parameter 'function'=<function preprocess_function at 0x7fe9d557caf0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2ac3ed12ad243d4afe3b17919dec71b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code sets the value of the test size to 15% of the total dataset size. Then, it processes the tokenized dataset and splits it into training and testing subsets using the specified test size."
      ],
      "metadata": {
        "id": "Tjn4wiaEgjAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_size=.15\n",
        "\n",
        "processed_dataset = tokenized_datasets.shuffle().train_test_split(test_size=test_size)"
      ],
      "metadata": {
        "id": "dznQAD5fgM_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code sets various configuration parameters for training a machine learning model using the Hugging Face Transformers library."
      ],
      "metadata": {
        "id": "Fsc3zAzAhJDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfFolder\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "num_train_epochs = 5\n",
        "train_batch_size = 4\n",
        "eval_batch_size = 4\n",
        "learning_rate = 5.6e-5\n",
        "weight_decay_rate= 0.01\n",
        "num_warmup_steps= 155\n",
        "output_dir=model_name.split(\"/\")[1]\n",
        "hub_token = HfFolder.get_token() # or your token directly \"hf_xxx\"\n",
        "hub_model_id = f'{model_name.split(\"/\")[1]}-tradetheevent'\n",
        "fp16= False #True\n",
        "\n",
        "# Train in mixed-precision float16\n",
        "# Comment this line out if you're using a GPU that will not benefit from this\n",
        "if fp16:\n",
        "  tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n"
      ],
      "metadata": {
        "id": "d7ZUhlUwgNCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code imports a model class called \"TFAutoModelForSeq2SeqLM\" from the Hugging Face Transformers library. It then loads a pre-trained sequence-to-sequence language model using the \"from_pretrained\" method and stores it in the variable \"model.\""
      ],
      "metadata": {
        "id": "gTma8vtqie_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSeq2SeqLM\n",
        "# load pre-trained model\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8d_u0XvgNE7",
        "outputId": "f082a767-d0c7-4610-d447-08d72b040676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
            "\n",
            "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at philschmid/tf-distilbart-cnn-12-6.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code imports a data collator class called \"DataCollatorForSeq2Seq\" from the Hugging Face Transformers library. It creates a data collator instance named \"data_collator\" that dynamically pads the input and label sequences.\n",
        "\n",
        "Then, it converts the processed training dataset (\"processed_dataset['train']\") and testing dataset (\"processed_dataset['test']\") into TensorFlow `tf.data.Dataset` objects. During conversion, it selects specific columns (\"input_ids,\" \"attention_mask,\" and \"labels\") from the dataset and shuffles the training dataset. It uses the previously created \"data_collator\" to collate the data into batches based on the specified batch sizes for training and evaluation (\"train_batch_size\" and \"eval_batch_size,\" respectively)."
      ],
      "metadata": {
        "id": "DNTNLPm0i8V3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# Data collator that will dynamically pad the inputs received, as well as the labels.\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")\n",
        "\n",
        "# converting our train dataset to tf.data.Dataset\n",
        "tf_train_dataset = processed_dataset[\"train\"].to_tf_dataset(\n",
        "   columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        "   shuffle=True,\n",
        "   batch_size=train_batch_size,\n",
        "   collate_fn=data_collator)\n",
        "\n",
        "# converting our test dataset to tf.data.Dataset\n",
        "tf_eval_dataset = processed_dataset[\"test\"].to_tf_dataset(\n",
        "   columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        "   shuffle=True,\n",
        "   batch_size=eval_batch_size,\n",
        "   collate_fn=data_collator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1ERw-1qhPdz",
        "outputId": "8b3cdbb3-e423-4088-ebd6-ff2e913e1528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code imports a function called \"create_optimizer\" from the Hugging Face Transformers library. It creates an optimizer with weight decay, which is commonly used for fine-tuning machine learning models.\n",
        "\n",
        "The number of training steps is calculated based on the length of the training dataset and the number of training epochs. The optimizer is initialized with the specified learning rate, weight decay rate, and the number of warm-up steps.\n",
        "\n",
        "After creating the optimizer and learning rate schedule, the model is compiled using the specified optimizer."
      ],
      "metadata": {
        "id": "yM8a_oAdjOQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "\n",
        "\n",
        "# create optimizer wight weigh decay\n",
        "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
        "optimizer, lr_schedule = create_optimizer(\n",
        "    init_lr=learning_rate,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=weight_decay_rate,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        ")\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=optimizer)\n"
      ],
      "metadata": {
        "id": "W8oxAUBthPgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, several callbacks are defined and stored in the \"callbacks\" list. First, the \"TensorboardCallback\" from TensorFlow is included to log training and evaluation metrics during model training. Then, an \"if\" condition checks if the \"hub_token\" variable has a value. If the condition is true (i.e., a valid Hugging Face Hub token is available), the \"PushToHubCallback\" from Hugging Face Transformers is included in the \"callbacks\" list. This callback is used to push the trained model and its associated tokenizer to the Hugging Face model hub, allowing easy sharing and version control of the model. The \"PushToHubCallback\" requires the \"output_dir,\" \"tokenizer,\" \"hub_model_id,\" and \"hub_token\" as inputs, which are provided accordingly in the callback definition."
      ],
      "metadata": {
        "id": "Eml5QX4aj0VA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "from tensorflow.keras.callbacks import TensorBoard as TensorboardCallback\n",
        "\n",
        "callbacks=[]\n",
        "\n",
        "callbacks.append(TensorboardCallback(log_dir=os.path.join(output_dir,\"logs\")))\n",
        "if hub_token:\n",
        "  callbacks.append(PushToHubCallback(output_dir=output_dir,\n",
        "                                     tokenizer=tokenizer,\n",
        "                                     hub_model_id=hub_model_id,\n",
        "                                     hub_token=hub_token))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "obCgLJNohPjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the model"
      ],
      "metadata": {
        "id": "D6hrxvPZj3eB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_results = model.fit(\n",
        "    tf_train_dataset,\n",
        "    validation_data=tf_eval_dataset,\n",
        "    callbacks=callbacks,\n",
        "    epochs=num_train_epochs,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6XUGIrGhPpO",
        "outputId": "161d00ca-ba36-4380-9b40-8a4841cfd88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "213/213 [==============================] - 1215s 5s/step - loss: 3.3304 - val_loss: 2.4883\n",
            "Epoch 2/5\n",
            "213/213 [==============================] - 1140s 5s/step - loss: 2.2314 - val_loss: 2.2614\n",
            "Epoch 3/5\n",
            "213/213 [==============================] - 1139s 5s/step - loss: 1.9043 - val_loss: 2.1848\n",
            "Epoch 4/5\n",
            "213/213 [==============================] - 1132s 5s/step - loss: 1.6874 - val_loss: 2.1762\n",
            "Epoch 5/5\n",
            "213/213 [==============================] - 1161s 5s/step - loss: 1.5278 - val_loss: 2.1991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculating ROUGE"
      ],
      "metadata": {
        "id": "0oJTIFbzj8jH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import sent_tokenize\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ_u8JonhPsN",
        "outputId": "d13bbafa-eff0-49a8-bc15-8ce137aab73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6joTP-4f4nH",
        "outputId": "55435394-ede4-45ae-e6aa-eef9e6dc673e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"rouge\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBkhXSSuhmNd",
        "outputId": "b32c83ca-6b47-4b34-bba7-fc088a19d628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-7154407f1f07>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"rouge\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataset):\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    for batch in tqdm(dataset):\n",
        "        predictions = model.generate(batch[\"input_ids\"])\n",
        "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "        labels = batch[\"labels\"].numpy()\n",
        "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "        decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "        decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "        all_predictions.extend(decoded_preds)\n",
        "        all_labels.extend(decoded_labels)\n",
        "        result = metric.compute(\n",
        "            predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "        )\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    return {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "results = evaluate(model, tf_eval_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqyb8WFLhmRF",
        "outputId": "6f4a1059-526d-4236-c60d-8a9aa41197a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/38 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/tf_utils.py:854: UserWarning: Using `max_length`'s default (142) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100%|██████████| 38/38 [1:03:26<00:00, 100.18s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROUGE scores"
      ],
      "metadata": {
        "id": "NsuuACgDkFO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)\n",
        "#1 epoch = {'rouge1': 34.0009, 'rouge2': 19.8162, 'rougeL': 27.9357, 'rougeLsum': 32.1849}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVsSdvychmUk",
        "outputId": "9b22ce35-879b-48e7-898e-a9d6958e3367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge1': 40.5229, 'rouge2': 27.8146, 'rougeL': 37.2549, 'rougeLsum': 39.8693}\n"
          ]
        }
      ]
    }
  ]
}